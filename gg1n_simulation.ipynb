{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqumo.simulations.networks.model import simulate_gg1, simulate_gg1_tandem\n",
    "from pyqumo.randoms import Poisson, Exponential, Distribution\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import random \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_num_stations': 3, 'real_time': 144.0, 'system_size': [(Countable: p=[0.0858, 0.0861, 0.0858, 0.0853, 0.0849, 0.0834, 0.083, 0.0814, 0.0805, 0.0815, 0.0818, 0.0804]), (Countable: p=[0.122, 0.113, 0.108, 0.101, 0.0961, 0.0899, 0.0812, 0.0729, 0.0642, 0.0551, 0.0492, 0.0471]), (Countable: p=[0.15, 0.134, 0.12, 0.107, 0.0942, 0.0845, 0.073, 0.0643, 0.0554, 0.0465, 0.0386, 0.0317])], 'queue_size': [(Countable: p=[0.172, 0.0858, 0.0853, 0.0849, 0.0834, 0.083, 0.0814, 0.0805, 0.0815, 0.0818, 0.0804]), (Countable: p=[0.235, 0.108, 0.101, 0.0961, 0.0899, 0.0812, 0.0729, 0.0642, 0.0551, 0.0492, 0.0471]), (Countable: p=[0.284, 0.12, 0.107, 0.0942, 0.0845, 0.073, 0.0643, 0.0554, 0.0465, 0.0386, 0.0317])], 'busy': [(Countable: p=[0.0858, 0.914]), (Countable: p=[0.122, 0.878]), (Countable: p=[0.15, 0.85])], 'drop_prob': [0.08129, 0.04534024232263964, 0.030185537854511866], 'delivery_prob': [0.8505675851377706, 1.0, 1.0], 'departures': [Statistics(avg=0.010881884436522481, var=0.00011734650493638703, std=0.010832659181216172, count=91861), Statistics(avg=0.011399353035992089, var=0.00012960616900929158, std=0.011384470519496794, count=87691), Statistics(avg=0.011754165138540468, var=0.00013665281255123782, std=0.011689859389712001, count=85044)], 'arrivals': [], 'wait_time': [Statistics(avg=0.049014797391013804, var=0.0014852702268638824, std=0.03853920376530738, count=91862), Statistics(avg=0.04110800668950603, var=0.0013447755722988536, std=0.03667118176850664, count=87692), Statistics(avg=0.036790163374136764, var=0.0012255536206879686, std=0.03500790797359889, count=85044)], 'response_time': [Statistics(avg=0.05896274358585192, var=0.001584260133152097, std=0.039802765395787476, count=91861), Statistics(avg=0.05112131989850917, var=0.0014463761942791983, std=0.038031252862339396, count=87691), Statistics(avg=0.04678001087993545, var=0.0013247951899893022, std=0.036397736055822236, count=85044)], 'delivery_delays': [Statistics(avg=0.15886035084656414, var=0.002818021850258252, std=0.05308504356462611, count=85044), Statistics(avg=0.0, var=0.0, std=0.0, count=0), Statistics(avg=0.0, var=0.0, std=0.0, count=0)]}\n",
      "Param                        Value\n",
      "---------------------------  -----------------------------------------------------------------------------------------------\n",
      "Number of stations           3\n",
      "Loss probability             [0.08129, 0.04534024232263964, 0.030185537854511866]\n",
      "[[ STATION #0 ]]\n",
      "System size PMF              [0.0858, 0.0861, 0.0858, 0.0853, 0.0849, 0.0834, 0.083, 0.0814, 0.0805, 0.0815, 0.0818, 0.0804]\n",
      "System size average          5.418833277370562\n",
      "System size std.dev.         3.453015623666049\n",
      "Queue size PMF               [0.172, 0.0858, 0.0853, 0.0849, 0.0834, 0.083, 0.0814, 0.0805, 0.0815, 0.0818, 0.0804]\n",
      "Queue size average           4.504639985520287\n",
      "Queue size std.dev.          3.327433894637332\n",
      "Busy PMF                     [0.0858, 0.914]\n",
      "Utilization                  0.9141922250895778\n",
      "Drop probability             0.08129\n",
      "Delivery probability         0.8505675851377706\n",
      "Departures, average          0.010881884436522481\n",
      "Departures, std.dev.         0.010832659181216172\n",
      "Response time, average       0.05896274358585192\n",
      "Response time, std.dev.      0.039802765395787476\n",
      "Wait time, average           0.049014797391013804\n",
      "Wait time, std.dev.          0.03853920376530738\n",
      "End-to-end delays, average   0.15886035084656414\n",
      "End-to-end delays, std.dev.  0.05308504356462611\n",
      "[[ STATION #1 ]]\n",
      "System size PMF              [0.122, 0.113, 0.108, 0.101, 0.0961, 0.0899, 0.0812, 0.0729, 0.0642, 0.0551, 0.0492, 0.0471]\n",
      "System size average          4.484705307283695\n",
      "System size std.dev.         3.2894675692280138\n",
      "Queue size PMF               [0.235, 0.108, 0.101, 0.0961, 0.0899, 0.0812, 0.0729, 0.0642, 0.0551, 0.0492, 0.0471]\n",
      "Queue size average           3.6062917198514235\n",
      "Queue size std.dev.          3.1363739551235503\n",
      "Busy PMF                     [0.122, 0.878]\n",
      "Utilization                  0.878413572940458\n",
      "Drop probability             0.04534024232263964\n",
      "Delivery probability         1.0\n",
      "Departures, average          0.011399353035992089\n",
      "Departures, std.dev.         0.011384470519496794\n",
      "Response time, average       0.05112131989850917\n",
      "Response time, std.dev.      0.038031252862339396\n",
      "Wait time, average           0.04110800668950603\n",
      "Wait time, std.dev.          0.03667118176850664\n",
      "End-to-end delays, average   0.0\n",
      "End-to-end delays, std.dev.  0.0\n",
      "[[ STATION #2 ]]\n",
      "System size PMF              [0.15, 0.134, 0.12, 0.107, 0.0942, 0.0845, 0.073, 0.0643, 0.0554, 0.0465, 0.0386, 0.0317]\n",
      "System size average          3.9798667390293487\n",
      "System size std.dev.         3.185032587861484\n",
      "Queue size PMF               [0.284, 0.12, 0.107, 0.0942, 0.0845, 0.073, 0.0643, 0.0554, 0.0465, 0.0386, 0.0317]\n",
      "Queue size average           3.1300358469522647\n",
      "Queue size std.dev.          3.012842554257314\n",
      "Busy PMF                     [0.15, 0.85]\n",
      "Utilization                  0.8498985158072478\n",
      "Drop probability             0.030185537854511866\n",
      "Delivery probability         1.0\n",
      "Departures, average          0.011754165138540468\n",
      "Departures, std.dev.         0.011689859389712001\n",
      "Response time, average       0.04678001087993545\n",
      "Response time, std.dev.      0.036397736055822236\n",
      "Wait time, average           0.036790163374136764\n",
      "Wait time, std.dev.          0.03500790797359889\n",
      "End-to-end delays, average   0.0\n",
      "End-to-end delays, std.dev.  0.0\n"
     ]
    }
   ],
   "source": [
    "results = simulate_gg1_tandem(\n",
    "    arrivals = Exponential(100),\n",
    "    services = [Exponential(100)] *  3,\n",
    "    queue_capacity = 10,\n",
    ")\n",
    "print(results.__dict__)\n",
    "print(results.tabulate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle for data generation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "\n",
    "@dataclass\n",
    "class MM1TandemInputData:\n",
    "    arrivals: List[Distribution]\n",
    "    services: List[Distribution]\n",
    "    queue_capacity: int = 10\n",
    "    max_packets: int = int(1e5)\n",
    "\n",
    "def extract_experiment_results(input_data, num_stations, results):\n",
    "    return  {\n",
    "        \"arrivals_exponential_rate\":    \";\".join([str(arrival.param) for arrival in input_data.arrivals]),\n",
    "\n",
    "        \"services_exponential_rate\":    \";\".join([str(service.param) for service in input_data.services]),\n",
    "        \n",
    "        \"queue_capacity\":               input_data.queue_capacity,\n",
    "\n",
    "        \"number_of_stations\":           num_stations,\n",
    "\n",
    "        \"queue_size_avg\":               np.mean([node_queue_size.mean for node_queue_size in results.queue_size]),\n",
    "\n",
    "        \"end_to_end_delay_avg\":         sum([node_delivery_delays.avg for node_delivery_delays in results.delivery_delays]),\n",
    "\n",
    "        \"drop_probabilities\":           1 - reduce(\n",
    "                                                lambda x, y: x * y, \n",
    "                                                [ (1 - node_drop_prob) for node_drop_prob in results.drop_prob ]\n",
    "                                            )\n",
    "    }\n",
    "\n",
    "def start_experiment(arrival_rate_min, arrival_rate_max, arrival_rate_step,\n",
    "                     service_rate_min, service_rate_max, service_rate_step,\n",
    "                     num_stations_min, num_stations_max, num_stations_step,\n",
    "                     queue_capacity, max_packets, service_dist = None,\n",
    "                     arrival_dist = None, save_name=\"\"):\n",
    "    \n",
    "    experiment_df = pd.DataFrame(columns=[\"arrivals_exponential_rate\", \"services_exponential_rate\",\n",
    "                                          \"queue_capacity\", \"number_of_stations\", \"queue_size_avg\", \n",
    "                                          \"end_to_end_delay_avg\", \"drop_probabilities\"])\n",
    "\n",
    "    total_num_iterations = ((arrival_rate_max - arrival_rate_min) / arrival_rate_step) * \\\n",
    "                           ((service_rate_max - service_rate_min) / service_rate_step) * \\\n",
    "                           ((num_stations_max - num_stations_min) / num_stations_step)\n",
    "\n",
    "    with tqdm(total=total_num_iterations) as pbar:\n",
    "        for num_stations in range(num_stations_min, num_stations_max, num_stations_step):\n",
    "            for arrival_rate in range(arrival_rate_min, arrival_rate_max, arrival_rate_step):\n",
    "                for service_rate in range(service_rate_min, service_rate_max, service_rate_step):\n",
    "\n",
    "                    input_data = MM1TandemInputData(\n",
    "                        [Exponential(arrival_rate) for _ in range(num_stations)],\n",
    "                        [Exponential(service_rate) for _ in range(num_stations)],\n",
    "                        queue_capacity,\n",
    "                        max_packets\n",
    "                    )\n",
    "\n",
    "                    # print(f\"Start simulation with input: {input_data.__dict__}\")\n",
    "\n",
    "                    results = simulate_gg1_tandem(**input_data.__dict__)\n",
    "\n",
    "                    experiment_df = pd.concat([\n",
    "                            experiment_df, \n",
    "                            pd.DataFrame([extract_experiment_results(input_data, num_stations, results)], columns=experiment_df.columns)\n",
    "                        ], \n",
    "                        ignore_index=True\n",
    "                    )\n",
    "\n",
    "                    # Raises future warning\n",
    "                    # experiment_df  = experiment_df.append(\n",
    "                    #     extract_experiment_results(input_data, num_stations, results), \n",
    "                    #     ignore_index=True\n",
    "                    # )\n",
    "\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    save_name = \"experiment-data/\" + save_name + datetime.today().strftime('-%Y-%m-%d-%H-%M-%S') + \".csv\"\n",
    "    experiment_df.to_csv(save_name)\n",
    "    return experiment_df, save_name\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, save_name = start_experiment(100, 1000, 10,  # arrivals\n",
    "                                 100, 1000, 10,  # services\n",
    "                                 5,   20,   1,   # num_stations\n",
    "                                 500, int(1e5),\n",
    "                                 Exponential,\n",
    "                                 Exponential,\n",
    "                                 \"experiment-various-num-stations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_list_from_str(str):\n",
    "    return list(map(float, str.split(';')))\n",
    "\n",
    "def get_learning_data_from_dataframe(df):\n",
    "    X = np.array([[]]).reshape(-1, 3)\n",
    "    Y = np.array([[]]).reshape(-1, 3)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        x_row = [row[\"number_of_stations\"]] + [decode_list_from_str(row[\"services_exponential_rate\"])[0]] + [decode_list_from_str(row[\"arrivals_exponential_rate\"])[0]]\n",
    "\n",
    "        X = np.append(X, [x_row], axis=0)\n",
    "        \n",
    "        y_row = [row[\"queue_size_avg\"]] + [row[\"end_to_end_delay_avg\"]] + [row[\"drop_probabilities\"]]\n",
    "        Y = np.append(Y, [y_row], axis=0)\n",
    "\n",
    "    return X, Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"experiment-data/experiment-various-num-stations-2024-05-12-03-27-51.csv\")\n",
    "\n",
    "X, Y = get_learning_data_from_dataframe(df)\n",
    "\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=RANDOM_STATE)\n",
    "print(f\"Train size: {X_train.shape[0]}\\nTest size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76daa2a716f9442c9c8e23cb02164224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = [\n",
    "    tree.DecisionTreeRegressor(random_state=RANDOM_STATE), \n",
    "    MultiOutputRegressor(Ridge(random_state=RANDOM_STATE)), \n",
    "    RandomForestRegressor(random_state=RANDOM_STATE), \n",
    "    MultiOutputRegressor(GradientBoostingRegressor(random_state=RANDOM_STATE)), \n",
    "    # MultiOutputRegressor(BaggingRegressor(estimator=SVR(random_state=RANDOM_STATE))),\n",
    "    # MLPRegressor(random_state=RANDOM_STATE, max_iter=5000),\n",
    "    \n",
    "]\n",
    "\n",
    "for model in tqdm(models):\n",
    "    model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e17c9fc44294494909ecf96a991499b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeRegressor(random_state=42)\n",
      "R^2 total\t=\t0.9796358303410923\n",
      "mse_total\t=\t28.38899393972575\n",
      "r2_[queue size avg.] = 0.9970093801827589\n",
      "mse_[queue size avg.] = 124.08277544768244\n",
      "r2_[end to end delay avg] = 0.9996166577913959\n",
      "mse_[end to end delay avg] = 18.880573274771248\n",
      "r2_[drop proba] = 0.9999407245794717\n",
      "mse_[drop proba] = 2.581426552862249\n",
      "\n",
      "Model: MultiOutputRegressor(estimator=Ridge(random_state=42))\n",
      "R^2 total\t=\t0.4872551765611264\n",
      "mse_total\t=\t877.7801766394674\n",
      "r2_[queue size avg.] = 0.9961597741098922\n",
      "mse_[queue size avg.] = 159.33348800925185\n",
      "r2_[end to end delay avg] = 0.996411341177448\n",
      "mse_[end to end delay avg] = 176.75052299632114\n",
      "r2_[drop proba] = 0.9819371980847267\n",
      "mse_[drop proba] = 786.6295349336134\n",
      "\n",
      "Model: RandomForestRegressor(random_state=42)\n",
      "R^2 total\t=\t0.9890150342928951\n",
      "mse_total\t=\t14.823511924314362\n",
      "r2_[queue size avg.] = 0.9981597553577827\n",
      "mse_[queue size avg.] = 76.35295579620178\n",
      "r2_[end to end delay avg] = 0.9999177538482681\n",
      "mse_[end to end delay avg] = 4.050830979444646\n",
      "r2_[drop proba] = 0.999918406208372\n",
      "mse_[drop proba] = 3.553384832697768\n",
      "\n",
      "Model: MultiOutputRegressor(estimator=GradientBoostingRegressor(random_state=42))\n",
      "R^2 total\t=\t0.9624886091568668\n",
      "mse_total\t=\t66.48561407552906\n",
      "r2_[queue size avg.] = 0.9993636302144819\n",
      "mse_[queue size avg.] = 26.403399303016105\n",
      "r2_[end to end delay avg] = 0.9999595726623229\n",
      "mse_[end to end delay avg] = 1.9911486243438334\n",
      "r2_[drop proba] = 0.9987146085298729\n",
      "mse_[drop proba] = 55.9784079511339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for model in tqdm(models):\n",
    "    prediction = model.predict(X_test)\n",
    "    r2_total = r2_score(Y_test, prediction)\n",
    "    mse_total = mean_squared_error(Y_test, prediction)\n",
    "\n",
    "    print(f\"Model: {model}\\nR^2 total\\t=\\t{r2_total}\\nmse_total\\t=\\t{mse_total}\")\n",
    "\n",
    "    idx_to_label = {\n",
    "        0: \"queue size avg.\",\n",
    "        1: \"end to end delay avg\",\n",
    "        2: \"drop proba\"\n",
    "    }\n",
    "\n",
    "    for idx in range(0, 3):\n",
    "        r2_idx = r2_score(Y_test[idx,:], prediction[idx, :])\n",
    "        mse_idx = mean_squared_error(Y_test[idx, :], prediction[idx, :])\n",
    "\n",
    "        print(f\"r2_[{idx_to_label[idx]}] = {r2_idx}\")\n",
    "        print(f\"mse_[{idx_to_label[idx]}] = {mse_idx}\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, \n",
    "            num_stations, \n",
    "            services_exponential_rate, \n",
    "            arrivals_exponential_rate):\n",
    "    \n",
    "    input_X = np.array([[num_stations, services_exponential_rate, arrivals_exponential_rate]]).reshape(-1, 3)\n",
    "\n",
    "    predicted_Y = model.predict(input_X)[0]\n",
    "\n",
    "    predicted_dict = {\n",
    "        \"queue_size_avg\":       predicted_Y[0],\n",
    "        \"end_to_end_delay_avg\": predicted_Y[1],\n",
    "        \"drop_probability\":     predicted_Y[2],\n",
    "    }\n",
    "\n",
    "    return predicted_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[2] # RandomForestRegressor\n",
    "\n",
    "predict(model, 7, 1000, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"experiment-data/experiment-various-num-stations-2024-05-12-03-27-51.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def plot_prediction(df, model, arrivals_rate, services_rate):\n",
    "    fiexd_rates = df[(df[\"arrivals_exponential_rate\"].map(lambda row: decode_list_from_str(row)[0]) == arrivals_rate) &\n",
    "                     (df[\"services_exponential_rate\"].map(lambda row: decode_list_from_str(row)[0]) == services_rate)]\n",
    "\n",
    "    num_stations = fiexd_rates[\"number_of_stations\"].to_numpy()\n",
    "    \n",
    "    queue_size_avg = fiexd_rates[\"queue_size_avg\"].to_numpy()\n",
    "\n",
    "    delays = fiexd_rates[\"end_to_end_delay_avg\"].to_numpy()\n",
    "    drop_probas = fiexd_rates[\"drop_probabilities\"].to_numpy()\n",
    "\n",
    "    arrivals_rates = np.array([arrivals_rate] * len(num_stations))\n",
    "    services_rates = np.array([services_rate] * len(num_stations))\n",
    "    \n",
    "\n",
    "    model_input = np.array([num_stations, services_rates, arrivals_rates]).reshape(-1, 3)\n",
    "\n",
    "\n",
    "    prediction = model.predict(model_input)\n",
    "\n",
    "    predicted_queue_sizes = prediction[:, 0]\n",
    "    predicted_delays = prediction[:, 1]\n",
    "    predicted_drop_probas = prediction[:, 2]\n",
    "\n",
    "    data_to_plot = [(queue_size_avg, predicted_queue_sizes, \"queue size avg.\"),\n",
    "                    (delays, predicted_delays, \"end to end delay\"),\n",
    "                    (drop_probas, predicted_drop_probas, \"drop probability\")]\n",
    "\n",
    "    for real_data, predicted_data, label in data_to_plot:\n",
    "        fig = plt.figure()\n",
    "        plt.grid()\n",
    "        plt.plot(num_stations, real_data, label=\"real\")\n",
    "        plt.plot(num_stations, predicted_data, label=\"predicted\")\n",
    "        plt.xlabel(\"Num stations\")\n",
    "        plt.ylabel(label)\n",
    "        plt.legend()\n",
    "        plt.title(f\"Arrivals rate = {arrivals_rate}\\nServices rate = {services_rate}\")\n",
    "        os.makedirs(f\"graphs/{model}/{label}\", exist_ok=True)\n",
    "        plt.savefig(f\"graphs/{model}/{label}/arrival={arrivals_rate};service={services_rate}.png\")\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71d0641ef3848c193b6272615a5bdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0621a4b4b1a843e59aff1878d944d41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611e0f95bca74351a6fb34e0e4714a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58c54c318104b828b03d2fb9b58aaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in models:\n",
    "    for arrival_rate in tqdm(range(100, 1000, 100)):\n",
    "        for service_rate in range(arrival_rate, 1000, 100):\n",
    "            plot_prediction(df, model, arrival_rate, service_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
